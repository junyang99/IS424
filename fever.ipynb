{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df[\"verifiable\"] == \"VERIFIABLE\") & (df[\"label\"].isin([\"SUPPORTS\", \"REFUTES\"]))].copy()\n",
    "df_filtered = df_filtered[[\"claim\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_filename = \"data/filtered_fever_data.xlsx\"\n",
    "df_filtered.to_excel(excel_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (70-30 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_filtered[\"claim\"], df_filtered[\"label\"], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TF-IDF Vectorization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF Model Performance ===\n",
      "Accuracy: 0.7740946483319673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     REFUTES       0.86      0.21      0.33      8987\n",
      "    SUPPORTS       0.77      0.99      0.86     23956\n",
      "\n",
      "    accuracy                           0.77     32943\n",
      "   macro avg       0.81      0.60      0.60     32943\n",
      "weighted avg       0.79      0.77      0.72     32943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Naive Bayes model\n",
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n=== TF-IDF Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N-Gram Processing (Unigram + Bigram + Trigram) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = TfidfVectorizer(ngram_range=(1,3))  # Includes unigrams, bigrams, and trigrams\n",
    "X_train_ngram = ngram_vectorizer.fit_transform(X_train)\n",
    "X_test_ngram = ngram_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N-Gram Model Performance ===\n",
      "Accuracy: 0.7779194366026166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     REFUTES       0.93      0.20      0.33      8987\n",
      "    SUPPORTS       0.77      0.99      0.87     23956\n",
      "\n",
      "    accuracy                           0.78     32943\n",
      "   macro avg       0.85      0.60      0.60     32943\n",
      "weighted avg       0.81      0.78      0.72     32943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ngram = MultinomialNB()\n",
    "model_ngram.fit(X_train_ngram, y_train)\n",
    "y_pred_ngram = model_ngram.predict(X_test_ngram)\n",
    "\n",
    "print(\"\\n=== N-Gram Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ngram))\n",
    "print(classification_report(y_test, y_pred_ngram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge TF-IDF & N-Gram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = hstack([X_train_tfidf, X_train_ngram])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_ngram])\n",
    "\n",
    "# Train & Evaluate Naive Bayes Model\n",
    "model_combined = MultinomialNB()\n",
    "model_combined.fit(X_train_combined, y_train)\n",
    "y_pred_combined = model_combined.predict(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Combined TF-IDF + N-Gram Model Performance ===\n",
      "Accuracy: 0.7830495097592812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     REFUTES       0.90      0.23      0.37      8987\n",
      "    SUPPORTS       0.77      0.99      0.87     23956\n",
      "\n",
      "    accuracy                           0.78     32943\n",
      "   macro avg       0.84      0.61      0.62     32943\n",
      "weighted avg       0.81      0.78      0.73     32943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Combined TF-IDF + N-Gram Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_combined))\n",
    "print(classification_report(y_test, y_pred_combined))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
